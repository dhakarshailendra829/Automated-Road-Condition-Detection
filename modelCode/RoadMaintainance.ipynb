{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4oMXMpn-2M",
        "outputId": "1b25a52c-77d4-47b1-87d1-0eb03677b292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FloodSatellight: 580 images found in data/FloodSatellight and subfolders\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing FloodSatellight: 100%|██████████| 580/580 [03:38<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FloodStreet: 882 images found in data/FloodStreet and subfolders\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing FloodStreet: 100%|██████████| 882/882 [05:13<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RoadData: 2009 images found in data/RoadData and subfolders\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing RoadData: 100%|██████████| 2009/2009 [11:52<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total images processed: 3471\n",
            "Feature vector shape: (3471, 2048)\n",
            "Shape after PCA: (3471, 680)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [05:42:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ML + CNN Model Accuracy: 0.9870503597122302\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "FloodSatellight       1.00      0.99      0.99       142\n",
            "    FloodStreet       0.99      0.96      0.97       161\n",
            "       RoadData       0.98      1.00      0.99       392\n",
            "\n",
            "       accuracy                           0.99       695\n",
            "      macro avg       0.99      0.98      0.99       695\n",
            "   weighted avg       0.99      0.99      0.99       695\n",
            "\n",
            "\n",
            "Saved all models in /models/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "DATASET_DIR = \"data\"\n",
        "CLASSES = [\"FloodSatellight\", \"FloodStreet\", \"RoadData\"]\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "def get_all_images(folder):\n",
        "    img_files = []\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img_files.append(os.path.join(root, f))\n",
        "    return img_files\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for label, cls in enumerate(CLASSES):\n",
        "    folder = os.path.join(DATASET_DIR, cls)\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Folder not found: {folder}\")\n",
        "        continue\n",
        "\n",
        "    img_files = get_all_images(folder)\n",
        "    if len(img_files) == 0:\n",
        "        print(f\"No images found in {folder} or its subfolders\")\n",
        "        continue\n",
        "    else:\n",
        "        print(f\"{cls}: {len(img_files)} images found in {folder} and subfolders\")\n",
        "\n",
        "    for path in tqdm(img_files, desc=f\"Processing {cls}\"):\n",
        "        try:\n",
        "            img = load_img(path, target_size=IMAGE_SIZE)\n",
        "            img_array = img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            img_array = preprocess_input(img_array)\n",
        "\n",
        "            feature_vector = feature_extractor.predict(img_array, verbose=0)\n",
        "            features.append(feature_vector.flatten())\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {path}: {e}\")\n",
        "\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "\n",
        "if X.shape[0] == 0:\n",
        "    raise ValueError(\"No features extracted! Check your dataset paths and image files.\")\n",
        "\n",
        "print(f\"\\nTotal images processed: {len(X)}\")\n",
        "print(f\"Feature vector shape: {X.shape}\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"Shape after PCA: {X_pca.shape}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "ml_model = XGBClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "ml_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ml_model.predict(X_test)\n",
        "print(\"\\nML + CNN Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=CLASSES))\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "pickle.dump(ml_model, open(\"models/ml_classifier.pkl\", \"wb\"))\n",
        "pickle.dump(pca, open(\"models/pca.pkl\", \"wb\"))\n",
        "pickle.dump(scaler, open(\"models/scaler.pkl\", \"wb\"))\n",
        "feature_extractor.save(\"models/resnet50_feature_extractor.h5\")\n",
        "\n",
        "print(\"\\nSaved all models in /models/\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
